{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.cuda as cuda\n",
    "\n",
    "# Use a GPU, i.e. cuda:0 device if it available.\n",
    "device = torch.device(\"cuda:0\" if cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images once\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "# import glob\n",
    "\n",
    "# width = 64\n",
    "# height =48\n",
    "# os.chdir(\"Data/imgs/train\")\n",
    "# for i in range(10):\n",
    "#     path = 'c'+ str(i) +'/*.jpg'\n",
    "#     path_resized = '/c'+str(i)+'/'\n",
    "#     for filename in glob.glob(path):\n",
    "#         img = Image.open(filename)\n",
    "#         img_resized = img.resize((width,height), Image.NEAREST)\n",
    "#         new_name = filename[3:-4] + '_resized.jpg'\n",
    "#         img_resized.save(\"../../imgs_resized\"+path_resized+new_name)\n",
    "# os.chdir(\"../../../\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Images to numpy arrays\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "os.chdir(\"Data/imgs_resized/train\")\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(10):\n",
    "    path = 'c'+ str(i) +'/*.jpg'\n",
    "    for filename in glob.glob(path):\n",
    "        img = cv2.imread(filename)\n",
    "#         img = img.astype(np.long)\n",
    "        img_new = np.array([img[:,:,i] for i in range(3)])\n",
    "        x_data.append(img_new)\n",
    "        y_data.append(np.array([i], dtype = np.long))\n",
    "    print(i)    \n",
    "os.chdir(\"../../../\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in Test images\n",
    "import pandas as pd\n",
    "\n",
    "test_labels = {}\n",
    "test_df = pd.read_csv('driver_imgs_list.csv')\n",
    "for index, row in test_df.iterrows():\n",
    "    test_labels[row['img']] = int(row['classname'][1])\n",
    "    if(index %10000 == 0):\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code to create pytorch dataset\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "# class DriverDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.len = len(y_data)\n",
    "#         self.x_data = torch.from_numpy(np.array(x_data))\n",
    "#         self.y_data = torch.from_numpy(np.array(y_data))\n",
    "# #         self.x_data = x_data\n",
    "# #         self.y_data = y_data\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "\n",
    "# dataset = DriverDataset()    \n",
    "    \n",
    "# transformations = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working code to convert data into pytorch dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as utils\n",
    "\n",
    "tensor_x = torch.stack([torch.Tensor(i) for i in x_data]) # transform to torch tensors\n",
    "tensor_y = torch.stack([torch.Tensor(i) for i in y_data])\n",
    "\n",
    "my_dataset = utils.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "train_loader = DataLoader(dataset=my_dataset,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(dataset=dataset,\n",
    "#                           batch_size=64,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_data[0].shape\n",
    "input_dim = input_shape[0]*input_shape[1]*input_shape[2]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\t\"\"\"NN Module that flattens the incoming tensor.\"\"\"\n",
    "\tdef forward(self, input):\n",
    "\t\treturn input.view(input.size(0), -1)\n",
    "\t\n",
    "def train(model, train_loader, test_loader, loss_func, opt, num_epochs=10):\n",
    "\tprint(\"starting\")\n",
    "\tall_training_loss = np.zeros((0,2))\n",
    "\tall_training_acc = np.zeros((0,2))\n",
    "\tall_test_loss = np.zeros((0,2))\n",
    "\tall_test_acc = np.zeros((0,2))\n",
    "\t\n",
    "\ttraining_step = 0\n",
    "\ttraining_loss, training_acc = 2.0, 0.0\n",
    "\tprint_every = 10\n",
    "\t\n",
    "\tstart = time.clock()\n",
    "\tprint(\"about to enter loop\")\n",
    "\tfor i in range(num_epochs):\n",
    "\t\tepoch_start = time.clock() \n",
    "\t \n",
    "\t\tmodel.train()\n",
    "\t\tprint(\"setting to train mode\")\n",
    "\t\tfor images, labels in train_loader:\n",
    "# \t\t\tprint('hi')\n",
    "\t\t\timages, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
    "\t\t\topt.zero_grad()\n",
    "\n",
    "\t\t\tpreds = model(images)\n",
    "#             targs.view(-1).long()\n",
    "\t\t\tloss = loss_func(preds, labels.view(-1).long())\n",
    "\t\t\tloss.backward()\n",
    "\t\t\topt.step()\n",
    "\t\t\t\n",
    "\t\t\ttraining_loss += loss.item()\n",
    "\t\t\ttraining_acc += (torch.argmax(preds, dim=1)==labels.view(-1).long()).float().mean()\n",
    "\t\t\t\n",
    "\t\t\tif training_step % print_every == 0:\n",
    "\t\t\t\ttraining_loss /= print_every\n",
    "\t\t\t\ttraining_acc /= print_every\n",
    "\t\t\t\t\n",
    "\t\t\t\tall_training_loss = np.concatenate((all_training_loss, [[training_step, training_loss]]))\n",
    "\t\t\t\tall_training_acc = np.concatenate((all_training_acc, [[training_step, training_acc]]))\n",
    "\t\t\t\t\n",
    "\t\t\t\tprint('  Epoch %d @ step %d: Train Loss: %3f, Train Accuracy: %3f' % (\n",
    "\t\t\t\t\t\ti, training_step, training_loss, training_acc))\n",
    "\t\t\t\ttraining_loss, training_acc = 0.0, 0.0\n",
    "\t\t\t\t\n",
    "\t\t\ttraining_step+=1\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\t\tprint(\"Setting to eval mode\")\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tvalidation_loss, validation_acc = 0.0, 0.0\n",
    "\t\t\tcount = 0\n",
    "\t\t\tfor images, labels in train_loader:\n",
    "\t\t\t\timages, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
    "\t\t\t\toutput = model(images)\n",
    "\t\t\t\tvalidation_loss+=loss_func(output,labels.view(-1).long())\n",
    "\t\t\t\tvalidation_acc+=(torch.argmax(output, dim=1) == labels.view(-1).long()).float().mean()\n",
    "\t\t\t\tcount += 1\n",
    "\t\t\tvalidation_loss/=count\n",
    "\t\t\tvalidation_acc/=count\n",
    "\t\t\t\n",
    "\t\t\tall_test_loss = np.concatenate((all_test_loss, [[training_step, validation_loss]]))\n",
    "\t\t\tall_test_acc = np.concatenate((all_test_acc, [[training_step, validation_acc]]))\n",
    "\t\t\t\n",
    "\t\t\tepoch_time = time.clock() - epoch_start\n",
    "\t\t\t\n",
    "\t\t\tprint('Epoch %d Test Loss: %3f, Test Accuracy: %3f, time: %.1fs' % (\n",
    "\t\t\t\t\ti, validation_loss, validation_acc, epoch_time))\n",
    "\t\t\t\n",
    "\ttotal_time = time.clock() - start\n",
    "\tprint('Final Test Loss: %3f, Test Accuracy: %3f, Total time: %.1fs' % (\n",
    "\t\t\tvalidation_loss, validation_acc, total_time))\n",
    "\n",
    "\treturn {'loss': { 'train': all_training_loss, 'test': all_test_loss },\n",
    "\t\t\t\t\t'accuracy': { 'train': all_training_acc, 'test': all_test_acc }}\n",
    "\n",
    "def plot_graphs(model_name, metrics):\n",
    "\tfor metric, values in metrics.items():\n",
    "\t\tfor name, v in values.items():\n",
    "\t\t\tplt.plot(v[:,0], v[:,1], label=name)\n",
    "\t\tplt.title(f'{metric} for {model_name}')\n",
    "\t\tplt.legend()\n",
    "\t\tplt.xlabel(\"Training Steps\")\n",
    "\t\tplt.ylabel(metric)\n",
    "\t\tplt.show()\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerModel(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(TwoLayerModel, self).__init__()\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\tFlatten(), \n",
    "\t\t\tnn.Linear(input_dim, 128), \n",
    "\t\t\tnn.ReLU(), \n",
    "\t\t\tnn.Linear(128, 10))\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.net(x)\n",
    "\n",
    "model = TwoLayerModel().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Training epoch should be about 15-20 sec each on GPU.\n",
    "metrics = train(model, train_loader, train_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(\"TwoLayerModel\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two layer model produced loss: 2.299817 and accuracy: 0.110948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "  # Your Code Here\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            Flatten())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(12288, 64),\n",
    "            nn.Linear(64, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return self.layer3(x)\n",
    "\n",
    "model = ConvModel().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "metrics = train(model, train_loader, train_loader, loss, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(\"ConvModel\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv model produced loss: 0.151928 and accuracy: 0.954401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
